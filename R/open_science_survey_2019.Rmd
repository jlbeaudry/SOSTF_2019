---
title: "Swinburne Open Science Task Force Survey (2019)"
author: "Jennifer L Beaudry"
date: "January 23, 2020"
output:
 # word_document: default
  html_document: default
csl: apa-old-doi-prefix.csl
bibliography: Beaudry_Library.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)
```

# Overview

We conducted a survey to examine people's current use of open science practices, 
to examine their perceptions of these practices, and to examine their perceived
barriers to using these practices. 

This document presents an overview of their responses. 

```{r library, include=FALSE}
#load the library
library(tinytex)
library(knitr)
library(here)
library(tidyverse)
library(skimr)
library(ggbeeswarm)
library(plyr) 
library(plotly)
```


```{r import data, include=FALSE}
#import the data. Here I'm using the original Qualtrics data, rather than Jordy's revised one.
df <- read_csv (here::here("data", "3_data_to_use.csv"))
```




```{r crisis_by_estimate, include = FALSE}

# filter rows with valid response for REPESTIMATE & rename variable accordingly
valid_rep_est <- filter(df, RepEstimate != "NA")

# calculate number of rows with a valid response 
nvalid_rep_est <- nrow(valid_rep_est)

# filter rows with valid responses for CRISIS & rename variable accordingly
nvalid_crisis <- filter(df, crisis != "NA") %>% 
  nrow()

# function to get percentages
perc <- function (x,y){  #x = variable; #y = n of valid cases from above
  c <- plyr::count (x)         #frequencies per level
  round (100*(c [,2] / y), 0) #rounding to 0 decimal places   
}

per_crisis <- perc(x = df$crisis, y = nvalid_crisis)  #percentage per level 
# divided by number of valid cases for the crisis variable

# output of `p` inserted in text below
```

## Estimates of Reproducibility by Perceived Crisis  

Participants were asked if they believed their field is experiencing a "reproducibility crisis". Of the `r nvalid_crisis` respondents who answered this question, `r per_crisis[1]`% indicated that they didn't know if there was a crisis, `r per_crisis[2]`% indicated there was no crisis, `r per_crisis[4]`% indicated that there was a slight crisis, and `r per_crisis[3]`% that there was a significant reproducibility crisis in their field.   

Participants were also asked to estimate the percentage of research publications 
their field that are reproducible. In the figure below, we plotted participants' 
reproducibility estimates according to their responses to the perceived 
crisis in their field. The black bar is the mean estimate of reproducibility 
perceived crisis. 


```{r crisis_by_estimate_stripchart, echo = FALSE, include = TRUE}
#estimates of reproducibility by levels of crisis as a stripchart 


title = sprintf("Estimates of reproducibility by perceived crisis in field (n = %d)",nvalid_rep_est)
x_name = "Do you think your field is experiencing a 'Reprodubility Crisis'?"
x_labels = c("Don't Know", "No Crisis", "Slight Crisis", "Significant Crisis")
y_name = "Estimated %age of reproducible studies"

p <- ggplot(data = valid_rep_est, 
       aes(x=crisis, y=RepEstimate)) + 
  geom_jitter(position=position_jitter(height=0,width=.15),
              fill="blue",
              colour="blue",
              size = 2.2,
              alpha=.5) +
  stat_summary(fun.y=mean,
               fun.ymin=mean,
               fun.ymax=mean,
               geom='crossbar',
               width=0.5) +
  scale_x_discrete(name = x_name, limits = x_labels) +
  scale_y_continuous(name = y_name) +
  coord_cartesian(ylim = c(0,100)) +
  theme_classic (base_size = 12) +
  ggtitle(title)

p

# if we want a separate file of the figure, use this code & it will be saved in 
  # the figs folder. This will be handy if we want to create slides.
#ggsave(here::here("figs", "reprod_estimates_by_crisis.png"))
```

   
## Experience with Open Science Practices

### Overall Experience with Open Science Practices

```{r os_experience, include = FALSE}

# filter rows with valid response for this variable & rename variable accordingly
valid_os_exp <- filter(df, OverallExperience != "NA")

# calculate number of rows with a valid response for this variable
nvalid_os_exp <- nrow(valid_os_exp)

per_os_exp <- perc(x = valid_os_exp$OverallExperience, y = nvalid_os_exp)

#count outputs in case that's what we are going to report instead...
c_os_exp <- count(valid_os_exp$OverallExperience)

# just an FYI that this does the same thing as the code above
#nvalid_os_exp <- df %>% 
  #filter (OverallExperience != "NA") %>% 
  #nrow()
```

Before we asked participants about their experience with open science practices, we explained that the practices enveloped by the umbrella term of "open science" were study preregistration, open materials and/or code, open data, pre-publication archiving, and open access publishing.   

The figure below shows participants' experience with open science practices in general. Of the `r nvalid_os_exp` participants who answered this question, `r per_os_exp[4]`% (or, `r c_os_exp[4,2]` if we are going to use frequencies here) reported that they were unaware of open science practices; `r per_os_exp[1]`% reported that they were aware of open science practices, but had not used them; `r per_os_exp[3]`% reported that they had some experience with open science practices; and only `r per_os_exp[2]`% reported that they had extensive experience with open science practices. 

```{r os_experience_bar, echo=FALSE, warning=TRUE, eval = FALSE}

title = sprintf("Experience with open science practices (n = %d)",nvalid_os_exp)
x_name = "What is your experience with open science practices?"
x_labels = c("Unaware", "Aware, But Not Used", "Some Experience", "Extensive Experience")
y_name = "Frequency"

p <- ggplot(data = valid_os_exp, 
       aes(x = OverallExperience)) + 
  geom_bar(
  colour = "black" , 
  fill = "blue") +
  scale_x_discrete(name = "What is your experience with open science practices?",
                   limits=c("Unaware", "Aware, But Not Used", "Some Experience", "Extensive Experience")) + 
  theme (text = element_text(size = 12)) +
  scale_y_continuous(name = "Frequency") +
  coord_cartesian(ylim = c(0,100)) +
  ggtitle(title)

p
```


```{r os_experience_pie, echo = FALSE}

# TOM, THIS WILL NEED TO BE UPDATED WITH YOUR PIE CHART FUNCTION# 

pie(c_os_exp$freq, labels=c_os_exp$x)
# I can play with the pie more to make it look different, but lets decide on one 
  # consistent style & then go from there....
  
```

```{r tables_os_experience, echo = FALSE}

# keeping this for now, but we likely won't use the table, right?
  # but, this is a good reminder that it's possible to change the order of the rows in the tables (arranged by descending frequency)
dplyr::arrange(c_os_exp, desc(freq)) %>% 
knitr::kable(col.names = c("Overall Experience", "Frequency"), caption = "Overall Experience with Open Science Practices")

```

### Experience with different types of open science practices
   
Next, we break down the results according to their experience with specific types of open science practices. 

#### Experience with Study Preregistration

```{r prereg_count, echo = FALSE, warning=TRUE}

# filter rows with valid responses for this variable
valid_prereg_exp <- filter(df, PreregExp1 != "NA")

# create object with the counts for each valid response for this variable
c_prereg_exp <- count(valid_prereg_exp$PreregExp1)

# calculate number of rows with a valid response for this variable
nvalid_prereg_exp <- nrow(valid_prereg_exp)

# calculate the percentage for each response
per_prereg_exp <- perc(x = df$PreregExp1, y = nvalid_prereg_exp)

```


Of the `r nvalid_prereg_exp` participants who answered this question, `r per_prereg_exp[4]`% were unaware of study preregistration; `r per_prereg_exp[1]`% were aware of study preregistration, but had not used it; `r per_prereg_exp[3]`% had some experience with it, but did not regularly preregister their studies; and `r per_prereg_exp[2]`% regularly preregistered their studies. 



```{r prereg_table, echo=FALSE, warning=TRUE}

dplyr::arrange(c_prereg_exp, desc(freq)) %>% 
knitr::kable (col.names = c("Preregistration Experience", "Frequency"), caption = "Experience with Study Preregistration")

```

### Experience with Open Materials and/or Code

```{r code_count, echo=FALSE, warning=TRUE}

# filter rows with valid responses for this variable
valid_code <- filter(df,CodeExp != "NA")

# calculate number of rows with a valid response for this variable
nvalid_code <- nrow(valid_code)


```

<!-- I use the `r ` inline insertion in the following to insert number of valid rows -->
This figure shows how many people have experience with open code and/or materials. A
total of `r nvalid_code` answered this question.

```{r code_figures, echo=FALSE, warning=TRUE}
# Tom, can you get in the habit of naming your r chunks, please?

# create labels for the graph elements
qtext <- "What is your experience with open materials and/or code?"

# here we use formatting to insert an integer number into the title text
title = sprintf("Experience with open materials and/or code (n = %d)",nvalid_code)

                
# create the plot
# use the 100*(..count..)/sum(..count..)) thing to create percentages

p <- ggplot(data = valid_code, aes(x=CodeExp)) + 
  geom_bar(aes(y=100*(..count..)/sum(..count..)),colour = "black" , fill = "blue" ) +
  scale_x_discrete(name = qtext,
                   limits=c("Unaware", "Aware, But Not Used", "Some Use", "Regular Use")) + 
  theme (text = element_text(size = 12)) +
  scale_y_continuous(name = "Percentage") + 
  coord_cartesian(ylim = c(0,100)) + 
  ggtitle(title)
p

# Now in pie chart form

valid_code_summary <- dplyr::count(valid_code,CodeExp)  

p <- pie(valid_code_summary$n,clockwise=TRUE,labels=valid_code_summary$CodeExp, init.angle=90, col=gray.colors(4,start=0.4,end=1.0))
p

# Now try the plotly pie chart

piedata <- valid_code[,'CodeExp']

p <- plot_ly(piedata, labels = ~CodeExp, type = 'pie',
             textposition = "inside",
             textinfo = 'label+percent',
             marker = list(colors = c("red","yellow","palegreen","darkseagreen"), 
                line=list(color="white", width=10)),
             showlegend=FALSE,
             sort=FALSE,
             direction="clockwise",
             rotation=0,
             hole=0.3,
             pull=0,
             title=list(text=title,position="top center",font=list(size=20, color="black")))
p

```

```{r code_tables, echo=FALSE}

c2 <- valid_code %>% 
  dplyr::count(CodeExp)  

knitr::kable(c2, caption = 'Experience with Open Materials & Code')
```

### Concerns with practices....

### Barriers...



```{r skim df, eval=FALSE, include=FALSE}
#These are chunks from the course I took, that I'm keeping now just for reference
#As a quick first pass, we can use the 'skim()' function to get a simple overview of each variable:
#skim(df)

# Now learning about group_by which appears to be a wonderful development!


frames %>%
  group_by(test_item, sample_size, n_obs, condition) %>%
  summarise(response = mean(response)) %>% #can call "response" anything you want.
  ungroup() #get in this habit because otherwise you might retain the grouping elsewhere.


# Now playing around with it to include more summary statistics, and to print out the different summary stats in a tiblle.

frames %>%
  group_by(test_item) %>%
  summarise(
    mean_resp = mean(response),
    sd_resp = sd(response),
    count = n()
  ) %>%
  ungroup


# Now play with filter to get summary stats from just a subset of the sample (their responses to only the 'small' objects).

average_response <- frames %>%
  group_by(test_item, sample_size, n_obs, condition) %>%
  summarise(response = mean(response)) %>%
  ungroup ()

average_response %>%
  filter(sample_size == "small") #this is not changing the average response variable because it still has everything in it.

#Now play with arrange to get summary stats from just a subset of the sample (their responses to only the 'small' objects), and arrange by condition.

average_response <- frames %>%
  group_by (test_item, sample_size, n_obs, condition) %>%
  summarise (response = mean(response)) %>%
  ungroup ()

average_response %>%
  filter (sample_size == "small") %>%
  arrange (condition)

# Now play with select to build on filter & arrange, but to only show some of the columns.

average_response <- frames %>%
  group_by (test_item, sample_size, n_obs, condition) %>%
  summarise (response = mean(response)) %>%
  ungroup ()

average_response_small <- average_response %>%
  filter (sample_size == "small") %>%
  arrange (condition) %>%
  select (condition, test_item, response)

average_response_small

# Now use mutate to create a new variable, which takes into account how many trials they completed.

average_response_small <- average_response_small %>%
  mutate (generalisation = response/9) %>%
  select (-response) #now remove response because we don't need it any longer

average_response_small

```
